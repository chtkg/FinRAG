{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import getpass\n",
    "import os\n",
    "\n",
    "\n",
    "def _set_env(key: str):\n",
    "    if key not in os.environ:\n",
    "        os.environ[key] = getpass.getpass(f\"{key}:\")\n",
    "\n",
    "os.environ[\"TAVILY_API_KEY\"] = \"\"\n",
    "_set_env(\"OPENAI_API_KEY\")\n",
    "_set_env(\"TAVILY_API_KEY\")\n",
    "\n",
    "local_llm = \"qwen2:latest\"\n",
    "model_tested = \"qwen2:latest\"\n",
    "metadata = f\"CRAG, {model_tested}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "USER_AGENT environment variable not set, consider setting it to identify your requests.\n"
     ]
    }
   ],
   "source": [
    "### Retrieval Grader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_community.document_loaders import WebBaseLoader, DirectoryLoader, TextLoader\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain_ollama import OllamaEmbeddings  \n",
    "\n",
    "finreport_dir = \"./FinRep\"\n",
    "\n",
    "# 加载本地 txt 文件\n",
    "loader = DirectoryLoader(finreport_dir, glob=\"report.txt\", loader_cls=TextLoader)\n",
    "docs = loader.load()\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter.from_tiktoken_encoder(\n",
    "    chunk_size=250, chunk_overlap=0\n",
    ")\n",
    "doc_splits = text_splitter.split_documents(docs)\n",
    "\n",
    "# 使用本地 Ollama 的 nomic-embed-text:latest 模型\n",
    "embedding_model = OllamaEmbeddings(model=\"nomic-embed-text:latest\")\n",
    "\n",
    "# Add to vectorDB\n",
    "vectorstore = Chroma.from_documents(\n",
    "    documents=doc_splits,\n",
    "    collection_name=\"rag-chroma\",\n",
    "    embedding=embedding_model,\n",
    ")\n",
    "retriever = vectorstore.as_retriever()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Document(metadata={'source': 'FinRep/report.txt'}, page_content='①生产研发'), Document(metadata={'source': 'FinRep/report.txt'}, page_content='为辅助生殖技术提供资助。'), Document(metadata={'source': 'FinRep/report.txt'}, page_content='豪华的医生团队阵容。'), Document(metadata={'source': 'FinRep/report.txt'}, page_content='降的趋势是明确的。')]\n",
      "{'score': 0}\n"
     ]
    }
   ],
   "source": [
    "### Retrieval Grader\n",
    "\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain_community.chat_models import ChatOllama\n",
    "from langchain_core.output_parsers import JsonOutputParser\n",
    "\n",
    "# LLM\n",
    "llm = ChatOllama(model=local_llm, format=\"json\", temperature=0)\n",
    "\n",
    "# Prompt\n",
    "prompt = PromptTemplate(\n",
    "    template=\"\"\"You are a teacher grading a quiz. You will be given: \n",
    "    1/ a QUESTION\n",
    "    2/ A FACT provided by the student\n",
    "\n",
    "    You are grading RELEVANCE RECALL:\n",
    "    A score of 1 means that ANY of the statements in the FACT are relevant to the QUESTION. \n",
    "    A score of 0 means that NONE of the statements in the FACT are relevant to the QUESTION. \n",
    "    1 is the highest (best) score. 0 is the lowest score you can give. \n",
    "\n",
    "    Explain your reasoning in a step-by-step manner. Ensure your reasoning and conclusion are correct. \n",
    "\n",
    "    Avoid simply stating the correct answer at the outset.\n",
    "\n",
    "    Question: {question} \\n\n",
    "    Fact: \\n\\n {documents} \\n\\n\n",
    "\n",
    "    Give a binary score 'yes' or 'no' score to indicate whether the document is relevant to the question. \\n\n",
    "    Provide the binary score as a JSON with a single key 'score' and no premable or explanation.\n",
    "    \"\"\",\n",
    "    input_variables=[\"question\", \"documents\"],\n",
    ")\n",
    "\n",
    "retrieval_grader = prompt | llm | JsonOutputParser()\n",
    "question = \"药明生物发展策略\"\n",
    "docs = retriever.invoke(question)\n",
    "doc_txt = docs[1].page_content\n",
    "print(docs)\n",
    "print(retrieval_grader.invoke({\"question\": question, \"documents\": doc_txt}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "药明生物的发展策略主要集中在生产研发领域，提供辅助生殖技术资助，并且拥有豪华的医生团队阵容。然而，报告中没有明确提及其发展趋势。\n"
     ]
    }
   ],
   "source": [
    "### Generate\n",
    "\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "# Prompt\n",
    "prompt = PromptTemplate(\n",
    "    template=\"\"\"You are an assistant for question-answering tasks. \n",
    "\n",
    "    Use the following documents to answer the question. \n",
    "\n",
    "    If you don't know the answer, just say that you don't know. \n",
    "\n",
    "    Use three sentences maximum and keep the answer concise:\n",
    "    Question: {question} \n",
    "    Documents: {documents} \n",
    "    Answer: \n",
    "    \"\"\",\n",
    "    input_variables=[\"question\", \"documents\"],\n",
    ")\n",
    "\n",
    "# LLM\n",
    "llm = ChatOllama(model=local_llm, temperature=0)\n",
    "\n",
    "# Chain\n",
    "rag_chain = prompt | llm | StrOutputParser()\n",
    "\n",
    "# Run\n",
    "generation = rag_chain.invoke({\"documents\": docs, \"question\": question})\n",
    "print(generation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Search\n",
    "\n",
    "from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "\n",
    "web_search_tool = TavilySearchResults(k=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "from typing_extensions import TypedDict\n",
    "from IPython.display import Image, display\n",
    "from langchain.schema import Document\n",
    "from langgraph.graph import START, END, StateGraph\n",
    "\n",
    "\n",
    "class GraphState(TypedDict):\n",
    "    \"\"\"\n",
    "    Represents the state of our graph.\n",
    "\n",
    "    Attributes:\n",
    "        question: question\n",
    "        generation: LLM generation\n",
    "        search: whether to add search\n",
    "        documents: list of documents\n",
    "    \"\"\"\n",
    "\n",
    "    question: str\n",
    "    generation: str\n",
    "    search: str\n",
    "    documents: List[str]\n",
    "    steps: List[str]\n",
    "\n",
    "\n",
    "def retrieve(state):\n",
    "    \"\"\"\n",
    "    Retrieve documents\n",
    "\n",
    "    Args:\n",
    "        state (dict): The current graph state\n",
    "\n",
    "    Returns:\n",
    "        state (dict): New key added to state, documents, that contains retrieved documents\n",
    "    \"\"\"\n",
    "    question = state[\"question\"]\n",
    "    documents = retriever.invoke(question)\n",
    "    steps = state[\"steps\"]\n",
    "    steps.append(\"retrieve_documents\")\n",
    "    return {\"documents\": documents, \"question\": question, \"steps\": steps}\n",
    "\n",
    "\n",
    "def generate(state):\n",
    "    \"\"\"\n",
    "    Generate answer\n",
    "\n",
    "    Args:\n",
    "        state (dict): The current graph state\n",
    "\n",
    "    Returns:\n",
    "        state (dict): New key added to state, generation, that contains LLM generation\n",
    "    \"\"\"\n",
    "\n",
    "    question = state[\"question\"]\n",
    "    documents = state[\"documents\"]\n",
    "    generation = rag_chain.invoke({\"documents\": documents, \"question\": question})\n",
    "    steps = state[\"steps\"]\n",
    "    steps.append(\"generate_answer\")\n",
    "    return {\n",
    "        \"documents\": documents,\n",
    "        \"question\": question,\n",
    "        \"generation\": generation,\n",
    "        \"steps\": steps,\n",
    "    }\n",
    "\n",
    "\n",
    "def grade_documents(state):\n",
    "    \"\"\"\n",
    "    Determines whether the retrieved documents are relevant to the question.\n",
    "\n",
    "    Args:\n",
    "        state (dict): The current graph state\n",
    "\n",
    "    Returns:\n",
    "        state (dict): Updates documents key with only filtered relevant documents\n",
    "    \"\"\"\n",
    "\n",
    "    question = state[\"question\"]\n",
    "    documents = state[\"documents\"]\n",
    "    steps = state[\"steps\"]\n",
    "    steps.append(\"grade_document_retrieval\")\n",
    "    filtered_docs = []\n",
    "    search = \"No\"\n",
    "    for d in documents:\n",
    "        score = retrieval_grader.invoke(\n",
    "            {\"question\": question, \"documents\": d.page_content}\n",
    "        )\n",
    "        grade = score[\"score\"]\n",
    "        if grade == \"yes\":\n",
    "            filtered_docs.append(d)\n",
    "        else:\n",
    "            search = \"Yes\"\n",
    "            continue\n",
    "    return {\n",
    "        \"documents\": filtered_docs,\n",
    "        \"question\": question,\n",
    "        \"search\": search,\n",
    "        \"steps\": steps,\n",
    "    }\n",
    "\n",
    "\n",
    "def web_search(state):\n",
    "    \"\"\"\n",
    "    Web search based on the re-phrased question.\n",
    "\n",
    "    Args:\n",
    "        state (dict): The current graph state\n",
    "\n",
    "    Returns:\n",
    "        state (dict): Updates documents key with appended web results\n",
    "    \"\"\"\n",
    "\n",
    "    question = state[\"question\"]\n",
    "    documents = state.get(\"documents\", [])\n",
    "    steps = state[\"steps\"]\n",
    "    steps.append(\"web_search\")\n",
    "    web_results = web_search_tool.invoke({\"query\": question})\n",
    "    documents.extend(\n",
    "        [\n",
    "            Document(page_content=d[\"content\"], metadata={\"url\": d[\"url\"]})\n",
    "            for d in web_results\n",
    "        ]\n",
    "    )\n",
    "    return {\"documents\": documents, \"question\": question, \"steps\": steps}\n",
    "\n",
    "\n",
    "def decide_to_generate(state):\n",
    "    \"\"\"\n",
    "    Determines whether to generate an answer, or re-generate a question.\n",
    "\n",
    "    Args:\n",
    "        state (dict): The current graph state\n",
    "\n",
    "    Returns:\n",
    "        str: Binary decision for next node to call\n",
    "    \"\"\"\n",
    "    search = state[\"search\"]\n",
    "    if search == \"Yes\":\n",
    "        return \"search\"\n",
    "    else:\n",
    "        return \"generate\"\n",
    "\n",
    "\n",
    "# Graph\n",
    "workflow = StateGraph(GraphState)\n",
    "\n",
    "# Define the nodes\n",
    "workflow.add_node(\"retrieve\", retrieve)  # retrieve\n",
    "workflow.add_node(\"grade_documents\", grade_documents)  # grade documents\n",
    "workflow.add_node(\"generate\", generate)  # generatae\n",
    "workflow.add_node(\"web_search\", web_search)  # web search\n",
    "\n",
    "# Build graph\n",
    "workflow.add_edge(START, \"retrieve\")\n",
    "workflow.add_edge(\"retrieve\", \"grade_documents\")\n",
    "workflow.add_conditional_edges(\n",
    "    \"grade_documents\",\n",
    "    decide_to_generate,\n",
    "    {\n",
    "        \"search\": \"web_search\",\n",
    "        \"generate\": \"generate\",\n",
    "    },\n",
    ")\n",
    "workflow.add_edge(\"web_search\", \"generate\")\n",
    "workflow.add_edge(\"generate\", END)\n",
    "\n",
    "custom_graph = workflow.compile()\n",
    "\n",
    "#display(Image(custom_graph.get_graph(xray=True).draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'药明康德成立于2000年12月。'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import uuid\n",
    "\n",
    "\n",
    "def predict_custom_agent_local_answer(example: dict):\n",
    "    config = {\"configurable\": {\"thread_id\": str(uuid.uuid4())}}\n",
    "    state_dict = custom_graph.invoke(\n",
    "        {\"question\": example[\"input\"], \"steps\": []}, config\n",
    "    )\n",
    "    return {\"response\": state_dict[\"generation\"], \"steps\": state_dict[\"steps\"]}\n",
    "\n",
    "\n",
    "example = {\"input\": \"药明成立时间\"}\n",
    "response = predict_custom_agent_local_answer(example)\n",
    "response[\"response\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "答案已写入文件 ./FinRep/CRAG/1_hop/answer000.txt\n",
      "答案已写入文件 ./FinRep/CRAG/1_hop/answer001.txt\n",
      "答案已写入文件 ./FinRep/CRAG/1_hop/answer002.txt\n",
      "答案已写入文件 ./FinRep/CRAG/1_hop/answer003.txt\n",
      "答案已写入文件 ./FinRep/CRAG/1_hop/answer004.txt\n",
      "答案已写入文件 ./FinRep/CRAG/1_hop/answer005.txt\n",
      "答案已写入文件 ./FinRep/CRAG/1_hop/answer006.txt\n",
      "答案已写入文件 ./FinRep/CRAG/1_hop/answer007.txt\n",
      "答案已写入文件 ./FinRep/CRAG/1_hop/answer008.txt\n",
      "答案已写入文件 ./FinRep/CRAG/1_hop/answer009.txt\n",
      "答案已写入文件 ./FinRep/CRAG/1_hop/answer010.txt\n",
      "答案已写入文件 ./FinRep/CRAG/1_hop/answer011.txt\n",
      "答案已写入文件 ./FinRep/CRAG/1_hop/answer012.txt\n",
      "答案已写入文件 ./FinRep/CRAG/1_hop/answer013.txt\n",
      "答案已写入文件 ./FinRep/CRAG/1_hop/answer014.txt\n",
      "答案已写入文件 ./FinRep/CRAG/1_hop/answer015.txt\n",
      "答案已写入文件 ./FinRep/CRAG/1_hop/answer016.txt\n",
      "答案已写入文件 ./FinRep/CRAG/1_hop/answer017.txt\n",
      "答案已写入文件 ./FinRep/CRAG/1_hop/answer018.txt\n",
      "答案已写入文件 ./FinRep/CRAG/1_hop/answer019.txt\n",
      "答案已写入文件 ./FinRep/CRAG/1_hop/answer020.txt\n",
      "答案已写入文件 ./FinRep/CRAG/1_hop/answer021.txt\n",
      "答案已写入文件 ./FinRep/CRAG/1_hop/answer022.txt\n",
      "答案已写入文件 ./FinRep/CRAG/1_hop/answer023.txt\n",
      "答案已写入文件 ./FinRep/CRAG/1_hop/answer024.txt\n",
      "答案已写入文件 ./FinRep/CRAG/1_hop/answer025.txt\n",
      "答案已写入文件 ./FinRep/CRAG/1_hop/answer026.txt\n",
      "答案已写入文件 ./FinRep/CRAG/1_hop/answer027.txt\n",
      "答案已写入文件 ./FinRep/CRAG/1_hop/answer028.txt\n",
      "答案已写入文件 ./FinRep/CRAG/1_hop/answer029.txt\n",
      "答案已写入文件 ./FinRep/CRAG/1_hop/answer030.txt\n",
      "答案已写入文件 ./FinRep/CRAG/1_hop/answer031.txt\n",
      "答案已写入文件 ./FinRep/CRAG/1_hop/answer032.txt\n",
      "答案已写入文件 ./FinRep/CRAG/1_hop/answer033.txt\n",
      "答案已写入文件 ./FinRep/CRAG/1_hop/answer034.txt\n",
      "答案已写入文件 ./FinRep/CRAG/1_hop/answer035.txt\n",
      "答案已写入文件 ./FinRep/CRAG/1_hop/answer036.txt\n",
      "答案已写入文件 ./FinRep/CRAG/1_hop/answer037.txt\n",
      "答案已写入文件 ./FinRep/CRAG/1_hop/answer038.txt\n",
      "答案已写入文件 ./FinRep/CRAG/1_hop/answer039.txt\n",
      "答案已写入文件 ./FinRep/CRAG/1_hop/answer040.txt\n",
      "答案已写入文件 ./FinRep/CRAG/1_hop/answer041.txt\n",
      "答案已写入文件 ./FinRep/CRAG/1_hop/answer042.txt\n",
      "答案已写入文件 ./FinRep/CRAG/1_hop/answer043.txt\n",
      "答案已写入文件 ./FinRep/CRAG/1_hop/answer044.txt\n",
      "答案已写入文件 ./FinRep/CRAG/1_hop/answer045.txt\n",
      "答案已写入文件 ./FinRep/CRAG/1_hop/answer046.txt\n",
      "答案已写入文件 ./FinRep/CRAG/1_hop/answer047.txt\n",
      "答案已写入文件 ./FinRep/CRAG/1_hop/answer048.txt\n",
      "答案已写入文件 ./FinRep/CRAG/1_hop/answer049.txt\n",
      "答案已写入文件 ./FinRep/CRAG/1_hop/answer050.txt\n",
      "答案已写入文件 ./FinRep/CRAG/1_hop/answer051.txt\n",
      "答案已写入文件 ./FinRep/CRAG/1_hop/answer052.txt\n",
      "答案已写入文件 ./FinRep/CRAG/1_hop/answer053.txt\n",
      "答案已写入文件 ./FinRep/CRAG/1_hop/answer054.txt\n",
      "答案已写入文件 ./FinRep/CRAG/1_hop/answer055.txt\n",
      "答案已写入文件 ./FinRep/CRAG/1_hop/answer056.txt\n",
      "答案已写入文件 ./FinRep/CRAG/1_hop/answer057.txt\n",
      "答案已写入文件 ./FinRep/CRAG/1_hop/answer058.txt\n",
      "答案已写入文件 ./FinRep/CRAG/1_hop/answer059.txt\n",
      "答案已写入文件 ./FinRep/CRAG/1_hop/answer060.txt\n",
      "答案已写入文件 ./FinRep/CRAG/1_hop/answer061.txt\n",
      "答案已写入文件 ./FinRep/CRAG/1_hop/answer062.txt\n",
      "答案已写入文件 ./FinRep/CRAG/1_hop/answer063.txt\n",
      "答案已写入文件 ./FinRep/CRAG/1_hop/answer064.txt\n",
      "答案已写入文件 ./FinRep/CRAG/1_hop/answer065.txt\n",
      "答案已写入文件 ./FinRep/CRAG/1_hop/answer066.txt\n",
      "答案已写入文件 ./FinRep/CRAG/1_hop/answer067.txt\n",
      "答案已写入文件 ./FinRep/CRAG/1_hop/answer068.txt\n",
      "答案已写入文件 ./FinRep/CRAG/1_hop/answer069.txt\n",
      "答案已写入文件 ./FinRep/CRAG/1_hop/answer070.txt\n",
      "答案已写入文件 ./FinRep/CRAG/1_hop/answer071.txt\n",
      "答案已写入文件 ./FinRep/CRAG/1_hop/answer072.txt\n",
      "答案已写入文件 ./FinRep/CRAG/1_hop/answer073.txt\n",
      "答案已写入文件 ./FinRep/CRAG/1_hop/answer074.txt\n",
      "答案已写入文件 ./FinRep/CRAG/1_hop/answer075.txt\n",
      "答案已写入文件 ./FinRep/CRAG/1_hop/answer076.txt\n",
      "答案已写入文件 ./FinRep/CRAG/1_hop/answer077.txt\n",
      "答案已写入文件 ./FinRep/CRAG/1_hop/answer078.txt\n",
      "答案已写入文件 ./FinRep/CRAG/1_hop/answer079.txt\n",
      "答案已写入文件 ./FinRep/CRAG/1_hop/answer080.txt\n",
      "答案已写入文件 ./FinRep/CRAG/1_hop/answer081.txt\n",
      "答案已写入文件 ./FinRep/CRAG/1_hop/answer082.txt\n",
      "答案已写入文件 ./FinRep/CRAG/1_hop/answer083.txt\n",
      "答案已写入文件 ./FinRep/CRAG/1_hop/answer084.txt\n",
      "答案已写入文件 ./FinRep/CRAG/1_hop/answer085.txt\n",
      "答案已写入文件 ./FinRep/CRAG/1_hop/answer086.txt\n",
      "答案已写入文件 ./FinRep/CRAG/1_hop/answer087.txt\n",
      "答案已写入文件 ./FinRep/CRAG/1_hop/answer088.txt\n",
      "答案已写入文件 ./FinRep/CRAG/1_hop/answer089.txt\n",
      "答案已写入文件 ./FinRep/CRAG/1_hop/answer090.txt\n",
      "答案已写入文件 ./FinRep/CRAG/1_hop/answer091.txt\n",
      "答案已写入文件 ./FinRep/CRAG/1_hop/answer092.txt\n",
      "答案已写入文件 ./FinRep/CRAG/1_hop/answer093.txt\n",
      "答案已写入文件 ./FinRep/CRAG/1_hop/answer094.txt\n",
      "答案已写入文件 ./FinRep/CRAG/1_hop/answer095.txt\n",
      "答案已写入文件 ./FinRep/CRAG/1_hop/answer096.txt\n",
      "答案已写入文件 ./FinRep/CRAG/1_hop/answer097.txt\n",
      "答案已写入文件 ./FinRep/CRAG/1_hop/answer098.txt\n",
      "答案已写入文件 ./FinRep/CRAG/1_hop/answer099.txt\n",
      "答案已写入文件 ./FinRep/CRAG/1_hop/answer100.txt\n",
      "答案已写入文件 ./FinRep/CRAG/1_hop/answer101.txt\n",
      "答案已写入文件 ./FinRep/CRAG/1_hop/answer102.txt\n",
      "答案已写入文件 ./FinRep/CRAG/1_hop/answer103.txt\n",
      "答案已写入文件 ./FinRep/CRAG/1_hop/answer104.txt\n",
      "答案已写入文件 ./FinRep/CRAG/1_hop/answer105.txt\n",
      "答案已写入文件 ./FinRep/CRAG/1_hop/answer106.txt\n",
      "答案已写入文件 ./FinRep/CRAG/1_hop/answer107.txt\n",
      "答案已写入文件 ./FinRep/CRAG/1_hop/answer108.txt\n",
      "答案已写入文件 ./FinRep/CRAG/1_hop/answer109.txt\n",
      "答案已写入文件 ./FinRep/CRAG/1_hop/answer110.txt\n",
      "答案已写入文件 ./FinRep/CRAG/1_hop/answer111.txt\n",
      "答案已写入文件 ./FinRep/CRAG/1_hop/answer112.txt\n",
      "答案已写入文件 ./FinRep/CRAG/1_hop/answer113.txt\n",
      "答案已写入文件 ./FinRep/CRAG/1_hop/answer114.txt\n",
      "答案已写入文件 ./FinRep/CRAG/1_hop/answer115.txt\n",
      "答案已写入文件 ./FinRep/CRAG/1_hop/answer116.txt\n",
      "答案已写入文件 ./FinRep/CRAG/1_hop/answer117.txt\n",
      "答案已写入文件 ./FinRep/CRAG/1_hop/answer118.txt\n",
      "答案已写入文件 ./FinRep/CRAG/1_hop/answer119.txt\n",
      "答案已写入文件 ./FinRep/CRAG/1_hop/answer120.txt\n",
      "答案已写入文件 ./FinRep/CRAG/1_hop/answer121.txt\n",
      "答案已写入文件 ./FinRep/CRAG/1_hop/answer122.txt\n",
      "答案已写入文件 ./FinRep/CRAG/1_hop/answer123.txt\n",
      "答案已写入文件 ./FinRep/CRAG/1_hop/answer124.txt\n",
      "答案已写入文件 ./FinRep/CRAG/1_hop/answer125.txt\n",
      "答案已写入文件 ./FinRep/CRAG/1_hop/answer126.txt\n",
      "答案已写入文件 ./FinRep/CRAG/1_hop/answer127.txt\n",
      "答案已写入文件 ./FinRep/CRAG/1_hop/answer128.txt\n",
      "答案已写入文件 ./FinRep/CRAG/1_hop/answer129.txt\n",
      "答案已写入文件 ./FinRep/CRAG/1_hop/answer130.txt\n",
      "答案已写入文件 ./FinRep/CRAG/1_hop/answer131.txt\n",
      "答案已写入文件 ./FinRep/CRAG/1_hop/answer132.txt\n",
      "答案已写入文件 ./FinRep/CRAG/1_hop/answer133.txt\n",
      "答案已写入文件 ./FinRep/CRAG/1_hop/answer134.txt\n",
      "答案已写入文件 ./FinRep/CRAG/1_hop/answer135.txt\n",
      "答案已写入文件 ./FinRep/CRAG/1_hop/answer136.txt\n",
      "答案已写入文件 ./FinRep/CRAG/1_hop/answer137.txt\n",
      "答案已写入文件 ./FinRep/CRAG/1_hop/answer138.txt\n",
      "答案已写入文件 ./FinRep/CRAG/1_hop/answer139.txt\n",
      "答案已写入文件 ./FinRep/CRAG/1_hop/answer140.txt\n",
      "答案已写入文件 ./FinRep/CRAG/1_hop/answer141.txt\n",
      "答案已写入文件 ./FinRep/CRAG/1_hop/answer142.txt\n",
      "答案已写入文件 ./FinRep/CRAG/1_hop/answer143.txt\n",
      "答案已写入文件 ./FinRep/CRAG/1_hop/answer144.txt\n",
      "答案已写入文件 ./FinRep/CRAG/1_hop/answer145.txt\n",
      "答案已写入文件 ./FinRep/CRAG/1_hop/answer146.txt\n",
      "答案已写入文件 ./FinRep/CRAG/1_hop/answer147.txt\n",
      "答案已写入文件 ./FinRep/CRAG/1_hop/answer148.txt\n",
      "答案已写入文件 ./FinRep/CRAG/1_hop/answer149.txt\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "\n",
    "\n",
    "def process_query(input_dir, output_dir):\n",
    "    \"\"\"\n",
    "    读取指定目录下的问题文件，处理问题，并写入答案到对应的文件中。\n",
    "\n",
    "    :param input_dir: 输入目录的路径，其中包含问题文件。\n",
    "    :param output_dir: 输出目录的路径，答案文件将写入此目录。\n",
    "    \"\"\"\n",
    "    # 确保输出目录存在\n",
    "    if not os.path.exists(output_dir):\n",
    "        os.makedirs(output_dir)\n",
    "\n",
    "    # 使用glob模块找到目录中所有的问题文件\n",
    "    query_files = glob.glob(os.path.join(input_dir, 'query*.txt'))\n",
    "\n",
    "    # 遍历问题文件\n",
    "    for i in range(0,150):  # 遍历query000.txt到query149.txt\n",
    "        query_file = os.path.join(input_dir, f\"query{i:03d}.txt\")\n",
    "        answer_file = os.path.join(output_dir, f\"answer{i:03d}.txt\")\n",
    "\n",
    "        if not os.path.exists(query_file):\n",
    "            print(f\"文件 {query_file} 不存在，跳过处理。\")\n",
    "            continue\n",
    "\n",
    "        # 读取问题文件内容\n",
    "        with open(query_file, \"r\", encoding=\"utf-8\") as f:\n",
    "            content = f.read()\n",
    "            lines = content.splitlines()\n",
    "\n",
    "        # 提取问题1\n",
    "        question = None\n",
    "        for line in lines:\n",
    "            if line.startswith(\"问题1：\"):\n",
    "                question = line.replace(\"问题1：\", \"\").strip()\n",
    "                break\n",
    "\n",
    "        if not question:\n",
    "            print(f\"文件 {query_file} 中未找到问题1，跳过处理。\")\n",
    "            continue\n",
    "\n",
    "        # 调用app.stream获取答案\n",
    "        inputs = {\"input\": question}\n",
    "        answer = \"抱歉，我无法回答您的问题。\"\n",
    "        try:\n",
    "            res = predict_custom_agent_local_answer(inputs)\n",
    "        except Exception as e:\n",
    "            print(f\"处理问题 {query_file} : {question}时发生错误\")\n",
    "        answer = res[\"response\"]\n",
    "        # 将问题和答案写入答案文件\n",
    "        with open(answer_file, \"w\", encoding=\"utf-8\") as f:\n",
    "            f.write(f\"问题：{question}\\n\")\n",
    "            f.write(f\"答案：{answer}\\n\")\n",
    "\n",
    "        print(f\"答案已写入文件 {answer_file}\")\n",
    "\n",
    "# 指定输入目录和输出文件\n",
    "input_directory = './FinRep/fin_queries'\n",
    "output_directory = './FinRep/CRAG/1_hop'\n",
    "\n",
    "# 调用函数执行处理操作\n",
    "process_query(input_directory, output_directory)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langgraph",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

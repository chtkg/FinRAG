{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import getpass\n",
    "import os\n",
    "\n",
    "\n",
    "def _set_env(key: str):\n",
    "    if key not in os.environ:\n",
    "        os.environ[key] = getpass.getpass(f\"{key}:\")\n",
    "\n",
    "\n",
    "_set_env(\"NOMIC_API_KEY\")\n",
    "local_llm = \"qwen2:latest\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "USER_AGENT environment variable not set, consider setting it to identify your requests.\n"
     ]
    }
   ],
   "source": [
    "### Retrieval Grader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_community.document_loaders import WebBaseLoader, DirectoryLoader, TextLoader\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain_ollama import OllamaEmbeddings  \n",
    "\n",
    "finreport_dir = \"./FinRep\"\n",
    "\n",
    "# 加载本地 txt 文件\n",
    "loader = DirectoryLoader(finreport_dir, glob=\"report.txt\", loader_cls=TextLoader)\n",
    "docs = loader.load()\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter.from_tiktoken_encoder(\n",
    "    chunk_size=250, chunk_overlap=0\n",
    ")\n",
    "doc_splits = text_splitter.split_documents(docs)\n",
    "\n",
    "# 使用本地 Ollama 的 nomic-embed-text:latest 模型\n",
    "embedding_model = OllamaEmbeddings(model=\"nomic-embed-text:latest\")\n",
    "\n",
    "# Add to vectorDB\n",
    "vectorstore = Chroma.from_documents(\n",
    "    documents=doc_splits,\n",
    "    collection_name=\"rag-chroma\",\n",
    "    embedding=embedding_model,\n",
    ")\n",
    "retriever = vectorstore.as_retriever()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'score': 'no'}\n"
     ]
    }
   ],
   "source": [
    "### Retrieval Grader\n",
    "\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain_ollama import ChatOllama \n",
    "from langchain_core.output_parsers import JsonOutputParser\n",
    "\n",
    "# LLM\n",
    "llm = ChatOllama(model=local_llm, format=\"json\", temperature=0)\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    template=\"\"\"You are a grader assessing relevance of a retrieved document to a user question. \\n \n",
    "    Here is the retrieved document: \\n\\n {document} \\n\\n\n",
    "    Here is the user question: {question} \\n\n",
    "    If the document contains keywords related to the user question, grade it as relevant. \\n\n",
    "    It does not need to be a stringent test. The goal is to filter out erroneous retrievals. \\n\n",
    "    Give a binary score 'yes' or 'no' score to indicate whether the document is relevant to the question. \\n\n",
    "    Provide the binary score as a JSON with a single key 'score' and no premable or explanation.\"\"\",\n",
    "    input_variables=[\"question\", \"document\"],\n",
    ")\n",
    "\n",
    "retrieval_grader = prompt | llm | JsonOutputParser()\n",
    "question = \"药明生物成立时间\"\n",
    "docs = retriever.invoke(question)\n",
    "doc_txt = docs[1].page_content\n",
    "#print(doc_txt)\n",
    "print(retrieval_grader.invoke({\"question\": question, \"document\": doc_txt}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wangke/anaconda3/envs/langgraph/lib/python3.12/site-packages/langsmith/client.py:253: LangSmithMissingAPIKeyWarning: API key must be provided when using hosted LangSmith API\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "关于药明生物的成立时间，提供的上下文中并未提及。因此，我无法提供确切的答案。\n"
     ]
    }
   ],
   "source": [
    "### Generate\n",
    "\n",
    "from langchain import hub\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "# Prompt\n",
    "prompt = hub.pull(\"rlm/rag-prompt\")\n",
    "\n",
    "# LLM\n",
    "llm = ChatOllama(model=local_llm, temperature=0)\n",
    "\n",
    "\n",
    "# Post-processing\n",
    "def format_docs(docs):\n",
    "    return \"\\n\\n\".join(doc.page_content for doc in docs)\n",
    "\n",
    "\n",
    "# Chain\n",
    "rag_chain = prompt | llm | StrOutputParser()\n",
    "\n",
    "# Run\n",
    "generation = rag_chain.invoke({\"context\": docs, \"question\": question})\n",
    "print(generation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'score': 'no'}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Hallucination Grader\n",
    "\n",
    "# LLM\n",
    "llm = ChatOllama(model=local_llm, format=\"json\", temperature=0)\n",
    "\n",
    "# Prompt\n",
    "prompt = PromptTemplate(\n",
    "    template=\"\"\"You are a grader assessing whether an answer is grounded in / supported by a set of facts. \\n \n",
    "    Here are the facts:\n",
    "    \\n ------- \\n\n",
    "    {documents} \n",
    "    \\n ------- \\n\n",
    "    Here is the answer: {generation}\n",
    "    Give a binary score 'yes' or 'no' score to indicate whether the answer is grounded in / supported by a set of facts. \\n\n",
    "    Provide the binary score as a JSON with a single key 'score' and no preamble or explanation.\"\"\",\n",
    "    input_variables=[\"generation\", \"documents\"],\n",
    ")\n",
    "\n",
    "hallucination_grader = prompt | llm | JsonOutputParser()\n",
    "hallucination_grader.invoke({\"documents\": docs, \"generation\": generation})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'score': 'yes'}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Answer Grader\n",
    "\n",
    "# LLM\n",
    "llm = ChatOllama(model=local_llm, format=\"json\", temperature=0)\n",
    "\n",
    "# Prompt\n",
    "prompt = PromptTemplate(\n",
    "    template=\"\"\"You are a grader assessing whether an answer is useful to resolve a question. \\n \n",
    "    Here is the answer:\n",
    "    \\n ------- \\n\n",
    "    {generation} \n",
    "    \\n ------- \\n\n",
    "    Here is the question: {question}\n",
    "    Give a binary score 'yes' or 'no' to indicate whether the answer is useful to resolve a question. \\n\n",
    "    Provide the binary score as a JSON with a single key 'score' and no preamble or explanation.\"\"\",\n",
    "    input_variables=[\"generation\", \"question\"],\n",
    ")\n",
    "\n",
    "answer_grader = prompt | llm | JsonOutputParser()\n",
    "answer_grader.invoke({\"question\": question, \"generation\": generation})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'When was WuXi Biologics founded?'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Question Re-writer\n",
    "\n",
    "# LLM\n",
    "llm = ChatOllama(model=local_llm, temperature=0)\n",
    "\n",
    "# Prompt\n",
    "re_write_prompt = PromptTemplate(\n",
    "    template=\"\"\"You a question re-writer that converts an input question to a better version that is optimized \\n \n",
    "     for vectorstore retrieval. Look at the initial and formulate an improved question. \\n\n",
    "     Here is the initial question: \\n\\n {question}. Improved question with no preamble: \\n \"\"\",\n",
    "    input_variables=[\"generation\", \"question\"],\n",
    ")\n",
    "\n",
    "question_rewriter = re_write_prompt | llm | StrOutputParser()\n",
    "question_rewriter.invoke({\"question\": question})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "\n",
    "from typing_extensions import TypedDict\n",
    "\n",
    "\n",
    "class GraphState(TypedDict):\n",
    "    \"\"\"\n",
    "    Represents the state of our graph.\n",
    "\n",
    "    Attributes:\n",
    "        question: question\n",
    "        generation: LLM generation\n",
    "        documents: list of documents\n",
    "    \"\"\"\n",
    "\n",
    "    question: str\n",
    "    generation: str\n",
    "    documents: List[str]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Nodes\n",
    "\n",
    "\n",
    "def retrieve(state):\n",
    "    \"\"\"\n",
    "    Retrieve documents\n",
    "\n",
    "    Args:\n",
    "        state (dict): The current graph state\n",
    "\n",
    "    Returns:\n",
    "        state (dict): New key added to state, documents, that contains retrieved documents\n",
    "    \"\"\"\n",
    "    # print(\"---RETRIEVE---\")\n",
    "    question = state[\"question\"]\n",
    "\n",
    "    # Retrieval\n",
    "    documents = retriever.invoke(question)\n",
    "    return {\"documents\": documents, \"question\": question}\n",
    "\n",
    "\n",
    "def generate(state):\n",
    "    \"\"\"\n",
    "    Generate answer\n",
    "\n",
    "    Args:\n",
    "        state (dict): The current graph state\n",
    "\n",
    "    Returns:\n",
    "        state (dict): New key added to state, generation, that contains LLM generation\n",
    "    \"\"\"\n",
    "    # print(\"---GENERATE---\")\n",
    "    question = state[\"question\"]\n",
    "    documents = state[\"documents\"]\n",
    "\n",
    "    # RAG generation\n",
    "    generation = rag_chain.invoke({\"context\": documents, \"question\": question})\n",
    "    return {\"documents\": documents, \"question\": question, \"generation\": generation}\n",
    "\n",
    "\n",
    "def grade_documents(state):\n",
    "    \"\"\"\n",
    "    Determines whether the retrieved documents are relevant to the question.\n",
    "\n",
    "    Args:\n",
    "        state (dict): The current graph state\n",
    "\n",
    "    Returns:\n",
    "        state (dict): Updates documents key with only filtered relevant documents\n",
    "    \"\"\"\n",
    "\n",
    "    # print(\"---CHECK DOCUMENT RELEVANCE TO QUESTION---\")\n",
    "    question = state[\"question\"]\n",
    "    documents = state[\"documents\"]\n",
    "\n",
    "    # Score each doc\n",
    "    filtered_docs = []\n",
    "    for d in documents:\n",
    "        score = retrieval_grader.invoke(\n",
    "            {\"question\": question, \"document\": d.page_content}\n",
    "        )\n",
    "        grade = score[\"score\"]\n",
    "        if grade == \"yes\":\n",
    "            # print(\"---GRADE: DOCUMENT RELEVANT---\")\n",
    "            filtered_docs.append(d)\n",
    "        else:\n",
    "            # print(\"---GRADE: DOCUMENT NOT RELEVANT---\")\n",
    "            continue\n",
    "    return {\"documents\": filtered_docs, \"question\": question}\n",
    "\n",
    "\n",
    "def transform_query(state):\n",
    "    \"\"\"\n",
    "    Transform the query to produce a better question.\n",
    "\n",
    "    Args:\n",
    "        state (dict): The current graph state\n",
    "\n",
    "    Returns:\n",
    "        state (dict): Updates question key with a re-phrased question\n",
    "    \"\"\"\n",
    "\n",
    "    # print(\"---TRANSFORM QUERY---\")\n",
    "    question = state[\"question\"]\n",
    "    documents = state[\"documents\"]\n",
    "\n",
    "    # Re-write question\n",
    "    better_question = question_rewriter.invoke({\"question\": question})\n",
    "    return {\"documents\": documents, \"question\": better_question}\n",
    "\n",
    "\n",
    "### Edges\n",
    "\n",
    "\n",
    "def decide_to_generate(state):\n",
    "    \"\"\"\n",
    "    Determines whether to generate an answer, or re-generate a question.\n",
    "\n",
    "    Args:\n",
    "        state (dict): The current graph state\n",
    "\n",
    "    Returns:\n",
    "        str: Binary decision for next node to call\n",
    "    \"\"\"\n",
    "\n",
    "    # print(\"---ASSESS GRADED DOCUMENTS---\")\n",
    "    state[\"question\"]\n",
    "    filtered_documents = state[\"documents\"]\n",
    "\n",
    "    if not filtered_documents:\n",
    "        # All documents have been filtered check_relevance\n",
    "        # We will re-generate a new query\n",
    "        # print(\n",
    "        #     \"---DECISION: ALL DOCUMENTS ARE NOT RELEVANT TO QUESTION, TRANSFORM QUERY---\"\n",
    "        # )\n",
    "        return \"transform_query\"\n",
    "    else:\n",
    "        # We have relevant documents, so generate answer\n",
    "        # print(\"---DECISION: GENERATE---\")\n",
    "        return \"generate\"\n",
    "\n",
    "\n",
    "def grade_generation_v_documents_and_question(state):\n",
    "    \"\"\"\n",
    "    Determines whether the generation is grounded in the document and answers question.\n",
    "\n",
    "    Args:\n",
    "        state (dict): The current graph state\n",
    "\n",
    "    Returns:\n",
    "        str: Decision for next node to call\n",
    "    \"\"\"\n",
    "\n",
    "    # print(\"---CHECK HALLUCINATIONS---\")\n",
    "    question = state[\"question\"]\n",
    "    documents = state[\"documents\"]\n",
    "    generation = state[\"generation\"]\n",
    "\n",
    "    score = hallucination_grader.invoke(\n",
    "        {\"documents\": documents, \"generation\": generation}\n",
    "    )\n",
    "    grade = score[\"score\"]\n",
    "\n",
    "    # Check hallucination\n",
    "    if grade == \"yes\":\n",
    "        # print(\"---DECISION: GENERATION IS GROUNDED IN DOCUMENTS---\")\n",
    "        # Check question-answering\n",
    "        # print(\"---GRADE GENERATION vs QUESTION---\")\n",
    "        score = answer_grader.invoke({\"question\": question, \"generation\": generation})\n",
    "        grade = score[\"score\"]\n",
    "        if grade == \"yes\":\n",
    "            # print(\"---DECISION: GENERATION ADDRESSES QUESTION---\")\n",
    "            return \"useful\"\n",
    "        else:\n",
    "            # print(\"---DECISION: GENERATION DOES NOT ADDRESS QUESTION---\")\n",
    "            return \"not useful\"\n",
    "    else:\n",
    "        # print(\"---DECISION: GENERATION IS NOT GROUNDED IN DOCUMENTS, RE-TRY---\")\n",
    "        return \"not supported\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import END, StateGraph, START\n",
    "\n",
    "workflow = StateGraph(GraphState)\n",
    "\n",
    "# Define the nodes\n",
    "workflow.add_node(\"retrieve\", retrieve)  # retrieve\n",
    "workflow.add_node(\"grade_documents\", grade_documents)  # grade documents\n",
    "workflow.add_node(\"generate\", generate)  # generatae\n",
    "workflow.add_node(\"transform_query\", transform_query)  # transform_query\n",
    "\n",
    "# Build graph\n",
    "workflow.add_edge(START, \"retrieve\")\n",
    "workflow.add_edge(\"retrieve\", \"grade_documents\")\n",
    "workflow.add_conditional_edges(\n",
    "    \"grade_documents\",\n",
    "    decide_to_generate,\n",
    "    {\n",
    "        \"transform_query\": \"transform_query\",\n",
    "        \"generate\": \"generate\",\n",
    "    },\n",
    ")\n",
    "workflow.add_edge(\"transform_query\", \"retrieve\")\n",
    "workflow.add_conditional_edges(\n",
    "    \"generate\",\n",
    "    grade_generation_v_documents_and_question,\n",
    "    {\n",
    "        \"not supported\": \"generate\",\n",
    "        \"useful\": END,\n",
    "        \"not useful\": \"transform_query\",\n",
    "    },\n",
    ")\n",
    "\n",
    "# Compile\n",
    "app = workflow.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"Node 'retrieve':\"\n",
      "'\\n---\\n'\n",
      "\"Node 'grade_documents':\"\n",
      "'\\n---\\n'\n",
      "\"Node 'transform_query':\"\n",
      "'\\n---\\n'\n",
      "\"Node 'retrieve':\"\n",
      "'\\n---\\n'\n",
      "\"Node 'grade_documents':\"\n",
      "'\\n---\\n'\n",
      "\"Node 'generate':\"\n",
      "'\\n---\\n'\n",
      "\"Node 'transform_query':\"\n",
      "'\\n---\\n'\n",
      "\"Node 'retrieve':\"\n",
      "'\\n---\\n'\n",
      "\"Node 'grade_documents':\"\n",
      "'\\n---\\n'\n",
      "\"Node 'generate':\"\n",
      "'\\n---\\n'\n",
      "('The document provided does not contain specific information about the '\n",
      " 'projected future growth metrics or the anticipated evolution of global '\n",
      " \"market share for Wuxi Biologics. It focuses on the company's capabilities \"\n",
      " 'and achievements, mentioning that by mid-2019, they had initiated 15 WuXiUP '\n",
      " 'projects with WuXiUP continuous cell culture expression levels reaching up '\n",
      " 'to 30-50g/L, which is ten times higher than traditional technologies.')\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "\n",
    "# Run\n",
    "inputs = {\"question\": \"药明生物未来发展前景如何，全球市场份额会如何变化？\"}\n",
    "for output in app.stream(inputs,{\"recursion_limit\": 25}):\n",
    "    for key, value in output.items():\n",
    "        # Node\n",
    "        pprint(f\"Node '{key}':\")\n",
    "        # Optional: print full state at each node\n",
    "        # pprint.pprint(value[\"keys\"], indent=2, width=80, depth=None)\n",
    "    pprint(\"\\n---\\n\")\n",
    "\n",
    "# Final generation\n",
    "pprint(value[\"generation\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "答案已写入文件 ./FinRep/SelfRAG/open/answer000.txt\n",
      "处理问题 ./FinRep/fin_queries/query001.txt : 雅生活服务的人才培养体制有什么特点，如何增强企业凝聚力？时发生错误\n",
      "答案已写入文件 ./FinRep/SelfRAG/open/answer001.txt\n",
      "答案已写入文件 ./FinRep/SelfRAG/open/answer002.txt\n",
      "答案已写入文件 ./FinRep/SelfRAG/open/answer003.txt\n",
      "处理问题 ./FinRep/fin_queries/query004.txt : 考虑到华虹半导体面临的各种挑战和风险，包括结构性问题、毛利率下滑以及竞争加剧，您如何看待公司未来的发展前景？时发生错误\n",
      "答案已写入文件 ./FinRep/SelfRAG/open/answer004.txt\n",
      "答案已写入文件 ./FinRep/SelfRAG/open/answer005.txt\n",
      "处理问题 ./FinRep/fin_queries/query006.txt : 文章中提到的新能源汽车、5G基站和TWS耳机对于钴和碳酸锂市场的影响综合预测是什么？时发生错误\n",
      "答案已写入文件 ./FinRep/SelfRAG/open/answer006.txt\n",
      "答案已写入文件 ./FinRep/SelfRAG/open/answer007.txt\n",
      "处理问题 ./FinRep/fin_queries/query008.txt : 2020-2022年锂供需结构会如何变化？时发生错误\n",
      "答案已写入文件 ./FinRep/SelfRAG/open/answer008.txt\n",
      "答案已写入文件 ./FinRep/SelfRAG/open/answer009.txt\n",
      "处理问题 ./FinRep/fin_queries/query010.txt : 日本的装配式住宅认定标准与中国有何不同？时发生错误\n",
      "答案已写入文件 ./FinRep/SelfRAG/open/answer010.txt\n",
      "处理问题 ./FinRep/fin_queries/query011.txt : 如何看待中国财险在当前市场环境下的投资价值，考虑到疫情的影响、公司估值和行业发展趋势？时发生错误\n",
      "答案已写入文件 ./FinRep/SelfRAG/open/answer011.txt\n",
      "答案已写入文件 ./FinRep/SelfRAG/open/answer012.txt\n",
      "答案已写入文件 ./FinRep/SelfRAG/open/answer013.txt\n",
      "处理问题 ./FinRep/fin_queries/query014.txt : 结合当前市场情况和机械设备行业发展趋势，你认为2020年机械设备领域将迎来什么样的机会和挑战？如何选择合适的投资策略？时发生错误\n",
      "答案已写入文件 ./FinRep/SelfRAG/open/answer014.txt\n",
      "答案已写入文件 ./FinRep/SelfRAG/open/answer015.txt\n",
      "答案已写入文件 ./FinRep/SelfRAG/open/answer016.txt\n",
      "答案已写入文件 ./FinRep/SelfRAG/open/answer017.txt\n",
      "答案已写入文件 ./FinRep/SelfRAG/open/answer018.txt\n",
      "答案已写入文件 ./FinRep/SelfRAG/open/answer019.txt\n",
      "处理问题 ./FinRep/fin_queries/query020.txt : 上海治臻可以实现双极板的什么生产？时发生错误\n",
      "答案已写入文件 ./FinRep/SelfRAG/open/answer020.txt\n",
      "答案已写入文件 ./FinRep/SelfRAG/open/answer021.txt\n",
      "答案已写入文件 ./FinRep/SelfRAG/open/answer022.txt\n",
      "处理问题 ./FinRep/fin_queries/query023.txt : 未来我国激光器市场发展面临的最大挑战是什么？时发生错误\n",
      "答案已写入文件 ./FinRep/SelfRAG/open/answer023.txt\n",
      "处理问题 ./FinRep/fin_queries/query024.txt : 旭辉控股集团的长期发展战略及目标是什么？他们如何实现规模、利润率、杠杆率的三者动态均衡发展？时发生错误\n",
      "答案已写入文件 ./FinRep/SelfRAG/open/answer024.txt\n",
      "答案已写入文件 ./FinRep/SelfRAG/open/answer025.txt\n",
      "答案已写入文件 ./FinRep/SelfRAG/open/answer026.txt\n",
      "答案已写入文件 ./FinRep/SelfRAG/open/answer027.txt\n",
      "答案已写入文件 ./FinRep/SelfRAG/open/answer028.txt\n",
      "答案已写入文件 ./FinRep/SelfRAG/open/answer029.txt\n",
      "处理问题 ./FinRep/fin_queries/query030.txt : 锦欣的扩张计划是什么？时发生错误\n",
      "答案已写入文件 ./FinRep/SelfRAG/open/answer030.txt\n",
      "答案已写入文件 ./FinRep/SelfRAG/open/answer031.txt\n",
      "答案已写入文件 ./FinRep/SelfRAG/open/answer032.txt\n",
      "处理问题 ./FinRep/fin_queries/query033.txt : 如果并购整合不及预期、外延拓展不及预期或者生育率下降超预期，会如何影响公司未来的发展和盈利能力？这对投资者的决策有什么样的影响？时发生错误\n",
      "答案已写入文件 ./FinRep/SelfRAG/open/answer033.txt\n",
      "答案已写入文件 ./FinRep/SelfRAG/open/answer034.txt\n",
      "处理问题 ./FinRep/fin_queries/query035.txt : 公司的毛利率和净利率如何变化，原因是什么？时发生错误\n",
      "答案已写入文件 ./FinRep/SelfRAG/open/answer035.txt\n",
      "处理问题 ./FinRep/fin_queries/query036.txt : 未来几年，大中华区人力资源服务市场可能会面临哪些挑战和机遇？这些因素将如何影响行业的发展趋势？时发生错误\n",
      "答案已写入文件 ./FinRep/SelfRAG/open/answer036.txt\n",
      "答案已写入文件 ./FinRep/SelfRAG/open/answer037.txt\n",
      "答案已写入文件 ./FinRep/SelfRAG/open/answer038.txt\n",
      "处理问题 ./FinRep/fin_queries/query039.txt : 本文给出的投资建议是什么？时发生错误\n",
      "答案已写入文件 ./FinRep/SelfRAG/open/answer039.txt\n",
      "答案已写入文件 ./FinRep/SelfRAG/open/answer040.txt\n",
      "答案已写入文件 ./FinRep/SelfRAG/open/answer041.txt\n",
      "答案已写入文件 ./FinRep/SelfRAG/open/answer042.txt\n",
      "答案已写入文件 ./FinRep/SelfRAG/open/answer043.txt\n",
      "答案已写入文件 ./FinRep/SelfRAG/open/answer044.txt\n",
      "答案已写入文件 ./FinRep/SelfRAG/open/answer045.txt\n",
      "答案已写入文件 ./FinRep/SelfRAG/open/answer046.txt\n",
      "答案已写入文件 ./FinRep/SelfRAG/open/answer047.txt\n",
      "答案已写入文件 ./FinRep/SelfRAG/open/answer048.txt\n",
      "处理问题 ./FinRep/fin_queries/query049.txt : 可能面临的风险有哪些？时发生错误\n",
      "答案已写入文件 ./FinRep/SelfRAG/open/answer049.txt\n",
      "答案已写入文件 ./FinRep/SelfRAG/open/answer050.txt\n",
      "答案已写入文件 ./FinRep/SelfRAG/open/answer051.txt\n",
      "答案已写入文件 ./FinRep/SelfRAG/open/answer052.txt\n",
      "处理问题 ./FinRep/fin_queries/query053.txt : 如何看待当前服务器行业的发展前景和潜在风险？时发生错误\n",
      "答案已写入文件 ./FinRep/SelfRAG/open/answer053.txt\n",
      "答案已写入文件 ./FinRep/SelfRAG/open/answer054.txt\n",
      "答案已写入文件 ./FinRep/SelfRAG/open/answer055.txt\n",
      "处理问题 ./FinRep/fin_queries/query056.txt : 未来几年车联网行业会有什么发展趋势？时发生错误\n",
      "答案已写入文件 ./FinRep/SelfRAG/open/answer056.txt\n",
      "答案已写入文件 ./FinRep/SelfRAG/open/answer057.txt\n",
      "答案已写入文件 ./FinRep/SelfRAG/open/answer058.txt\n",
      "答案已写入文件 ./FinRep/SelfRAG/open/answer059.txt\n",
      "答案已写入文件 ./FinRep/SelfRAG/open/answer060.txt\n",
      "处理问题 ./FinRep/fin_queries/query061.txt : 新冠疫情可能对化工产品价格产生什么样的影响，并且这种影响在时间上大致如何分布？时发生错误\n",
      "答案已写入文件 ./FinRep/SelfRAG/open/answer061.txt\n",
      "答案已写入文件 ./FinRep/SelfRAG/open/answer062.txt\n",
      "答案已写入文件 ./FinRep/SelfRAG/open/answer063.txt\n",
      "答案已写入文件 ./FinRep/SelfRAG/open/answer064.txt\n",
      "答案已写入文件 ./FinRep/SelfRAG/open/answer065.txt\n",
      "答案已写入文件 ./FinRep/SelfRAG/open/answer066.txt\n",
      "答案已写入文件 ./FinRep/SelfRAG/open/answer067.txt\n",
      "答案已写入文件 ./FinRep/SelfRAG/open/answer068.txt\n",
      "答案已写入文件 ./FinRep/SelfRAG/open/answer069.txt\n",
      "答案已写入文件 ./FinRep/SelfRAG/open/answer070.txt\n",
      "答案已写入文件 ./FinRep/SelfRAG/open/answer071.txt\n",
      "答案已写入文件 ./FinRep/SelfRAG/open/answer072.txt\n",
      "答案已写入文件 ./FinRep/SelfRAG/open/answer073.txt\n",
      "答案已写入文件 ./FinRep/SelfRAG/open/answer074.txt\n",
      "处理问题 ./FinRep/fin_queries/query075.txt : 生活服务业和旅游业的复工情况如何？时发生错误\n",
      "答案已写入文件 ./FinRep/SelfRAG/open/answer075.txt\n",
      "答案已写入文件 ./FinRep/SelfRAG/open/answer076.txt\n",
      "答案已写入文件 ./FinRep/SelfRAG/open/answer077.txt\n",
      "答案已写入文件 ./FinRep/SelfRAG/open/answer078.txt\n",
      "答案已写入文件 ./FinRep/SelfRAG/open/answer079.txt\n",
      "答案已写入文件 ./FinRep/SelfRAG/open/answer080.txt\n",
      "答案已写入文件 ./FinRep/SelfRAG/open/answer081.txt\n",
      "答案已写入文件 ./FinRep/SelfRAG/open/answer082.txt\n",
      "处理问题 ./FinRep/fin_queries/query083.txt : 报告对周期需求的预测是什么？时发生错误\n",
      "答案已写入文件 ./FinRep/SelfRAG/open/answer083.txt\n",
      "答案已写入文件 ./FinRep/SelfRAG/open/answer084.txt\n",
      "处理问题 ./FinRep/fin_queries/query085.txt : 文章中提到的玻纤行业龙头企业的名称是什么？时发生错误\n",
      "答案已写入文件 ./FinRep/SelfRAG/open/answer085.txt\n",
      "处理问题 ./FinRep/fin_queries/query086.txt : 如何评估疫情对经济的长期影响，以及随着财政和货币政策的实施，经济增速会如何变化？时发生错误\n",
      "答案已写入文件 ./FinRep/SelfRAG/open/answer086.txt\n",
      "答案已写入文件 ./FinRep/SelfRAG/open/answer087.txt\n",
      "答案已写入文件 ./FinRep/SelfRAG/open/answer088.txt\n",
      "答案已写入文件 ./FinRep/SelfRAG/open/answer089.txt\n",
      "答案已写入文件 ./FinRep/SelfRAG/open/answer090.txt\n",
      "答案已写入文件 ./FinRep/SelfRAG/open/answer091.txt\n",
      "处理问题 ./FinRep/fin_queries/query092.txt : 疫情对股价和估值的影响是什么？时发生错误\n",
      "答案已写入文件 ./FinRep/SelfRAG/open/answer092.txt\n",
      "处理问题 ./FinRep/fin_queries/query093.txt : 在投资旅游相关行业时，需要注意哪些风险？时发生错误\n",
      "答案已写入文件 ./FinRep/SelfRAG/open/answer093.txt\n",
      "答案已写入文件 ./FinRep/SelfRAG/open/answer094.txt\n",
      "答案已写入文件 ./FinRep/SelfRAG/open/answer095.txt\n",
      "答案已写入文件 ./FinRep/SelfRAG/open/answer096.txt\n",
      "答案已写入文件 ./FinRep/SelfRAG/open/answer097.txt\n",
      "答案已写入文件 ./FinRep/SelfRAG/open/answer098.txt\n",
      "答案已写入文件 ./FinRep/SelfRAG/open/answer099.txt\n",
      "处理问题 ./FinRep/fin_queries/query100.txt : 文章建议关注哪些银行和券商？时发生错误\n",
      "答案已写入文件 ./FinRep/SelfRAG/open/answer100.txt\n",
      "答案已写入文件 ./FinRep/SelfRAG/open/answer101.txt\n",
      "答案已写入文件 ./FinRep/SelfRAG/open/answer102.txt\n",
      "答案已写入文件 ./FinRep/SelfRAG/open/answer103.txt\n",
      "答案已写入文件 ./FinRep/SelfRAG/open/answer104.txt\n",
      "处理问题 ./FinRep/fin_queries/query105.txt : 在报告中提到的这些板块（如社服板块、酒店板块、人资板块、新兴服务业、景区板块、餐饮板块和教育板块）中，长期依然看好的龙头企业有哪些？时发生错误\n",
      "答案已写入文件 ./FinRep/SelfRAG/open/answer105.txt\n",
      "答案已写入文件 ./FinRep/SelfRAG/open/answer106.txt\n",
      "答案已写入文件 ./FinRep/SelfRAG/open/answer107.txt\n",
      "答案已写入文件 ./FinRep/SelfRAG/open/answer108.txt\n",
      "处理问题 ./FinRep/fin_queries/query109.txt : 新零售的供应链与传统供应链有什么不同？时发生错误\n",
      "答案已写入文件 ./FinRep/SelfRAG/open/answer109.txt\n",
      "处理问题 ./FinRep/fin_queries/query110.txt : 新东方在线依托哪两个集团有望成长为线上教育龙头？时发生错误\n",
      "答案已写入文件 ./FinRep/SelfRAG/open/answer110.txt\n",
      "答案已写入文件 ./FinRep/SelfRAG/open/answer111.txt\n",
      "答案已写入文件 ./FinRep/SelfRAG/open/answer112.txt\n",
      "答案已写入文件 ./FinRep/SelfRAG/open/answer113.txt\n",
      "答案已写入文件 ./FinRep/SelfRAG/open/answer114.txt\n",
      "答案已写入文件 ./FinRep/SelfRAG/open/answer115.txt\n",
      "处理问题 ./FinRep/fin_queries/query116.txt : 零售药店在疫情期间的表现如何？时发生错误\n",
      "答案已写入文件 ./FinRep/SelfRAG/open/answer116.txt\n",
      "处理问题 ./FinRep/fin_queries/query117.txt : 未来电商直播行业的发展趋势如何？在这一背景下，生态服务商的价值会如何体现？时发生错误\n",
      "答案已写入文件 ./FinRep/SelfRAG/open/answer117.txt\n",
      "答案已写入文件 ./FinRep/SelfRAG/open/answer118.txt\n",
      "答案已写入文件 ./FinRep/SelfRAG/open/answer119.txt\n",
      "答案已写入文件 ./FinRep/SelfRAG/open/answer120.txt\n",
      "答案已写入文件 ./FinRep/SelfRAG/open/answer121.txt\n",
      "答案已写入文件 ./FinRep/SelfRAG/open/answer122.txt\n",
      "处理问题 ./FinRep/fin_queries/query123.txt : 纳米晶软磁材料相比其他类型的软磁材料有什么优势？时发生错误\n",
      "答案已写入文件 ./FinRep/SelfRAG/open/answer123.txt\n",
      "答案已写入文件 ./FinRep/SelfRAG/open/answer124.txt\n",
      "答案已写入文件 ./FinRep/SelfRAG/open/answer125.txt\n",
      "处理问题 ./FinRep/fin_queries/query126.txt : 安泰科技在无线充电磁性材料领域有哪些发展？时发生错误\n",
      "答案已写入文件 ./FinRep/SelfRAG/open/answer126.txt\n",
      "处理问题 ./FinRep/fin_queries/query127.txt : 请分析保利物业当前的细分业务毛利率水平及其对未来综合毛利率的影响？时发生错误\n",
      "答案已写入文件 ./FinRep/SelfRAG/open/answer127.txt\n",
      "答案已写入文件 ./FinRep/SelfRAG/open/answer128.txt\n",
      "答案已写入文件 ./FinRep/SelfRAG/open/answer129.txt\n",
      "答案已写入文件 ./FinRep/SelfRAG/open/answer130.txt\n",
      "答案已写入文件 ./FinRep/SelfRAG/open/answer131.txt\n",
      "答案已写入文件 ./FinRep/SelfRAG/open/answer132.txt\n",
      "答案已写入文件 ./FinRep/SelfRAG/open/answer133.txt\n",
      "处理问题 ./FinRep/fin_queries/query134.txt : 特斯拉在中国市场的未来发展前景如何，公司如何布局充电设施，以及对其产品销售可能产生的影响？时发生错误\n",
      "答案已写入文件 ./FinRep/SelfRAG/open/answer134.txt\n",
      "答案已写入文件 ./FinRep/SelfRAG/open/answer135.txt\n",
      "答案已写入文件 ./FinRep/SelfRAG/open/answer136.txt\n",
      "处理问题 ./FinRep/fin_queries/query137.txt : 疫情结束后，哪些公司可能在远程协同办公领域受益？时发生错误\n",
      "答案已写入文件 ./FinRep/SelfRAG/open/answer137.txt\n",
      "处理问题 ./FinRep/fin_queries/query138.txt : 同程艺龙面临的主要风险是什么？时发生错误\n",
      "答案已写入文件 ./FinRep/SelfRAG/open/answer138.txt\n",
      "处理问题 ./FinRep/fin_queries/query139.txt : 公建物业市场化改革对公司的盈利能力有何影响？时发生错误\n",
      "答案已写入文件 ./FinRep/SelfRAG/open/answer139.txt\n",
      "处理问题 ./FinRep/fin_queries/query140.txt : 开放性问题，根据文本中关于保利物业发展战略和风险分析的内容，你认为保利物业在未来发展中应该如何平衡快速扩张和项目管理质量？时发生错误\n",
      "答案已写入文件 ./FinRep/SelfRAG/open/answer140.txt\n",
      "答案已写入文件 ./FinRep/SelfRAG/open/answer141.txt\n",
      "答案已写入文件 ./FinRep/SelfRAG/open/answer142.txt\n",
      "答案已写入文件 ./FinRep/SelfRAG/open/answer143.txt\n",
      "处理问题 ./FinRep/fin_queries/query144.txt : 根据中俄东线天然气管道工程（中段）复工以及全国钛白粉行业产量和产能的双增长，如何推断化工行业在2020年的发展趋势，以及面临的机遇与挑战？时发生错误\n",
      "答案已写入文件 ./FinRep/SelfRAG/open/answer144.txt\n",
      "答案已写入文件 ./FinRep/SelfRAG/open/answer145.txt\n",
      "答案已写入文件 ./FinRep/SelfRAG/open/answer146.txt\n",
      "处理问题 ./FinRep/fin_queries/query147.txt : 哪些公司有关于股权转让、合作开发和可转换公司债券发行的公告？时发生错误\n",
      "答案已写入文件 ./FinRep/SelfRAG/open/answer147.txt\n",
      "答案已写入文件 ./FinRep/SelfRAG/open/answer148.txt\n",
      "答案已写入文件 ./FinRep/SelfRAG/open/answer149.txt\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "\n",
    "# 假设app已经定义并可以调用\n",
    "# 例如：from your_app import app\n",
    "\n",
    "def process_query(input_dir, output_dir):\n",
    "    \"\"\"\n",
    "    读取指定目录下的问题文件，处理问题，并写入答案到对应的文件中。\n",
    "\n",
    "    :param input_dir: 输入目录的路径，其中包含问题文件。\n",
    "    :param output_dir: 输出目录的路径，答案文件将写入此目录。\n",
    "    \"\"\"\n",
    "    # 确保输出目录存在\n",
    "    if not os.path.exists(output_dir):\n",
    "        os.makedirs(output_dir)\n",
    "\n",
    "    # 使用glob模块找到目录中所有的问题文件\n",
    "    query_files = glob.glob(os.path.join(input_dir, 'query*.txt'))\n",
    "\n",
    "    # 遍历问题文件\n",
    "    for i in range(0,150):  # 遍历query000.txt到query149.txt\n",
    "        query_file = os.path.join(input_dir, f\"query{i:03d}.txt\")\n",
    "        answer_file = os.path.join(output_dir, f\"answer{i:03d}.txt\")\n",
    "\n",
    "        if not os.path.exists(query_file):\n",
    "            print(f\"文件 {query_file} 不存在，跳过处理。\")\n",
    "            continue\n",
    "\n",
    "        # 读取问题文件内容\n",
    "        with open(query_file, \"r\", encoding=\"utf-8\") as f:\n",
    "            content = f.read()\n",
    "            lines = content.splitlines()\n",
    "\n",
    "        # 提取问题1\n",
    "        question = None\n",
    "        for line in lines:\n",
    "            if line.startswith(\"问题3：\"):\n",
    "                question = line.replace(\"问题3：\", \"\").strip()\n",
    "                break\n",
    "\n",
    "        if not question:\n",
    "            print(f\"文件 {query_file} 中未找到问题3，跳过处理。\")\n",
    "            continue\n",
    "\n",
    "        # 调用app.stream获取答案\n",
    "        inputs = {\"question\": question}\n",
    "        answer = \"抱歉，我无法回答您的问题。\"\n",
    "        try:\n",
    "            for output in app.stream(inputs,{\"recursion_limit\": 25}):\n",
    "                for key, value in output.items():\n",
    "                    continue\n",
    "            answer = value[\"generation\"]\n",
    "        except Exception as e:\n",
    "            print(f\"处理问题 {query_file} : {question}时发生错误\")\n",
    "\n",
    "        # 将问题和答案写入答案文件\n",
    "        with open(answer_file, \"w\", encoding=\"utf-8\") as f:\n",
    "            f.write(f\"问题：{question}\\n\")\n",
    "            f.write(f\"答案：{answer}\\n\")\n",
    "\n",
    "        print(f\"答案已写入文件 {answer_file}\")\n",
    "\n",
    "# 指定输入目录和输出文件\n",
    "input_directory = './FinRep/fin_queries'\n",
    "output_directory = './FinRep/SelfRAG/open'\n",
    "\n",
    "# 调用函数执行处理操作\n",
    "process_query(input_directory, output_directory)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langgraph",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
